### Pyspark Interpreter  
* Abrir terminal como administrador.
* Dentro da pasta do Spark Executar.
```./bin/pyspark```  
---------
### First commands on Terminal:  
* Reselient distribuited dataset  
   
``` rdd = sc.textFile("README.md") ```  
  
* Spark JOB
``` rdd.count() ```  
---------
### BigData DATA www.grouplens.org  
---------
Para executar o Spark RDD Job:  
* Abrir terminar como admin e ir at√© a pasta do script.  
``` spark-submit nome_do_script.py ```



